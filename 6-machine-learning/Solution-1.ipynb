{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 1\n",
    "Apply your skills to classify protein foldType with Decision Tree Classifier\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmtfPyspark.ml import SparkMultiClassClassifier, datasetBalancer                                 \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import mltoolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[4]\") \\\n",
    "                    .appName(\"datasetClassifierProblemset\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO-1: Read in data from parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetFile = './intput_features/'\n",
    "data = spark.read.parquet(parquetFile).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO-2: Select alpha, beta, alpha+beta foldtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data: 14443\n"
     ]
    }
   ],
   "source": [
    "data = data.where((data.foldType == 'alpha') |\\\n",
    "                  (data.foldType == 'beta') |\\\n",
    "                  (data.foldType == 'alpha+beta'))\n",
    "print(f\"Total number of data: {data.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO-3: Downsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (balanced)  : 3777\n",
      "+----------+-----+\n",
      "|  foldType|count|\n",
      "+----------+-----+\n",
      "|alpha+beta| 1290|\n",
      "|      beta| 1253|\n",
      "|     alpha| 1234|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = 'foldType'\n",
    "\n",
    "data = datasetBalancer.downsample(data, label, 1)\n",
    "print(f\"Dataset size (balanced)  : {data.count()}\")\n",
    "    \n",
    "data.groupby(label).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO-4: Decision Tree Classifier with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class\tTrain\tTest\n",
      "alpha+beta\t1150\t140\n",
      "beta\t1128\t125\n",
      "alpha\t1099\t135\n",
      "\n",
      "Sample predictions: DecisionTreeClassifier\n",
      "+----------------+----------+----------+----------+----------+--------------------+------------+------------------+--------------------+----------+--------------+\n",
      "|structureChainId|     alpha|      beta|      coil|  foldType|            features|indexedLabel|     rawPrediction|         probability|prediction|predictedLabel|\n",
      "+----------------+----------+----------+----------+----------+--------------------+------------+------------------+--------------------+----------+--------------+\n",
      "|          1P1M.A|0.36386138|0.23514852| 0.4009901|alpha+beta|[-0.2208177057692...|         0.0|[342.0,56.0,105.0]|[0.67992047713717...|       0.0|    alpha+beta|\n",
      "|          2HJ1.B|      0.15|      0.35|       0.5|alpha+beta|[-0.1719372452062...|         0.0|[342.0,56.0,105.0]|[0.67992047713717...|       0.0|    alpha+beta|\n",
      "|          2XED.B| 0.4512195|  0.199187| 0.3495935|alpha+beta|[-0.2095412626821...|         0.0|[342.0,56.0,105.0]|[0.67992047713717...|       0.0|    alpha+beta|\n",
      "|          3WKX.A|0.39269406|0.17503805|0.43226787|alpha+beta|[-0.1679776978238...|         0.0|[342.0,56.0,105.0]|[0.67992047713717...|       0.0|    alpha+beta|\n",
      "|          4JHT.A|0.15920398| 0.3482587|0.49253732|alpha+beta|[0.00524336394694...|         0.0|[102.0,18.0,122.0]|[0.42148760330578...|       2.0|         alpha|\n",
      "+----------------+----------+----------+----------+----------+--------------------+------------+------------------+--------------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total time taken: 5.847317934036255\n",
      "\n",
      "Method\tDecisionTreeClassifier\n",
      "F\t0.6342003046910765\n",
      "Accuracy\t0.6325\n",
      "Precision\t0.6445922412668127\n",
      "Recall\t0.6325000000000001\n",
      "False Positive Rate\t0.18922120332497688\n",
      "True Positive Rate\t0.6325000000000001\n",
      "\t\n",
      "Confusion Matrix\n",
      "['alpha+beta', 'beta', 'alpha']\n",
      "DenseMatrix([[85., 15., 40.],\n",
      "             [42., 73., 10.],\n",
      "             [31.,  9., 95.]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "mcc = SparkMultiClassClassifier(dtc, label, 0.1)\n",
    "matrics = mcc.fit(data)\n",
    "for k,v in matrics.items(): print(f\"{k}\\t{v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: Decision Tree Classifier with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class\tTrain\tTest\n",
      "\n",
      "alpha+beta\t1152\t138\n",
      "\n",
      "beta\t1128\t125\n",
      "\n",
      "alpha\t1119\t115\n",
      "\n",
      "Total time taken: 0.3240659236907959\n",
      "\n",
      "Methods\tDecisionTreeClassifier\n",
      "F Score\t0.73018623821153\n",
      "Accuracy\t0.7328042328042328\n",
      "Precision\t0.7316380681625885\n",
      "Recall\t0.7328042328042328\n",
      "False Positive Rate\t0.13359262153690984\n",
      "True Positive Rate\t0.737487922705314\n",
      "\t\n",
      "Confusion Matrix\n",
      "['alpha+beta' 'beta' 'alpha']\n",
      "[[ 85  23  30]\n",
      " [ 12 105   8]\n",
      " [ 22   6  87]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df = data.toPandas()\n",
    "dtc = DecisionTreeClassifier()\n",
    "mcc = mltoolkit.MultiClassClassifier(dtc, 'foldType', testFraction=0.1)\n",
    "matrics = mcc.fit(df)\n",
    "for k,v in matrics.items(): print(f\"{k}\\t{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
